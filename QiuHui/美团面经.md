# 美团面试

## 一面
1. 用CNN得到的特征和RNN得到的特征有什么区别？   
- 用CNN得到的特征只包含局部的特征，而用RNN得到的特征可以包含比较远的信息。
- 用CNN的到的特征通常是没有顺序关系的，而RNN得到的特征包含顺序关系。
2. 用seq2seq生成模型，如何解决重复生成的问题，如何解决多样性的问题。
- 重复性：可以采用coverage机制。coverage机制指的是对之前的所有的生成结果的attention值进行累加，然后对这个值求loss。因此，如果此前已经attention过的词，再次attention到的概率就会变小。这样有助于解决重复生成的问题。
- 多样性：对于一条样本生成多个结果的多样性，我们的做法是强制控制首个字不一样，因此在beam-search的时候，如果生成五个结果，那么五个结果通常是不一样的；对于全局多样性，我们不希望多个case生成的结果是一样的，所以我们维护了一个全局表，如果某一条生成非常多的话，就丢弃。
3. maxpooling阶段，梯度是怎么反向传播的？
- 正向传播的过程中，需要记录最大的值，反向传播的梯度只传播给最大的那个，其他的是0。如果是meanpooling，那么反向传播将梯度求平均之后传递给每个值。
4. 文本纠错研究现状？你们为啥这么做。
- SOTA：smt+nmt，但是很慢。
- 商用：检错+纠错，序列标注+LM。
- 我们参考了谷歌论文，所以这么做的。
5. 编程题  
给定一个字符串和一个单词表，例如s='abcde'，d={‘ab’，‘c’，‘de’,'cde'}，找出所有字符串能拆分成单词表中单词组合数。在这个例子中有两种，{'ab','c','de'}和{'ab','cde'}，返回2.   
LeetCode139的变种。简单讲了一下思路，没说太明白。没让写，补上。

```
def wordBreak(s, wordDict):
    """
    :type s: str
    :type wordDict: List[str]
    :rtype: bool
    """
    if not s or not wordDict:
        return 0
    dp = [0] * (len(s) + 1)
    dp[0] = 1
    for i in range(1, len(s) + 1):
        for j in range(0, i):
            if dp[j] and s[j:i] in wordDict:
                dp[i] = dp[i] + dp[j]
    return dp[-1]
```

## 二面
1. 项目1有没有尝试过不同的特征，如果有多个特征，如果用DSSM模型。怎么输入。
- 没有，其他特征都在规则引擎里了。多特征，就分别卷积池化，然后拼起来。也可以把文本拼起来。看看哪个效果好。
2. 文本生成如何解决重复生成，问了两次。
- coverage机制。
3、预训练语言模型用的那个，有没有试过其他的。
- 试过，bert, roberta-wwm,小参数bert。我们挑了个在公开测试集上最好的，roberta-wwm。
4、什么是知识蒸馏，有没有用过模型蒸馏。模型蒸馏咋做的。
- 没有，知识蒸馏就是把大模型的知识迁移到小模型。我说我觉得用浅层bert多训练一些steps可能也差不多。
5、有没有做过推荐相关，推荐现在主流模型有啥，DCN有啥优点，模型架构咋样的。
- 没有，了解过一些，deepfm，dcn。dcn的优点是不需要显示地做特征交叉，交叉在交叉网络中实现，可以产生高纬的交叉特征。  
模型架构：输入端将离散特征转为稠密，然后和稠密特征拼起来输入，包含交叉网络和深度网络，交叉网络处理特征交叉，深度网络就是普通前馈神经网络，最后将两者的结果拼起来。
6. 有没有做过对话，闲聊机器人评判标准有哪些。
- 没有,但是了解一些。  
客观：BLEU，Rouge-1,2,L。  
主观：流畅性，相关性，多样性。这三个生成相关的任务都能用。
7. 有没有用过知识图谱，知识图谱主流任务有哪些。
- 毕设简单做过知识图谱查询，将查询转化为子图匹配去做，忘光了。主流任务包括构建与查询。
8. 什么叫子图同构，子图异构。
- 不知道。
9. 有没有用过图神经网络。
- 没有，但是了解过一些，deepwalk。
10. 编程题
找数组中第K大的数。

```
def findKthLargest(nums, k):
    """
    :type nums: List[int]
    :type k: int
    :rtype: int
    """

    def partition(nums, left, right):
        pivot = nums[left]
        while left < right:
            while left < right and nums[right] >= pivot:
                right -= 1
            nums[left] = nums[right]
            while left < right and nums[left] < pivot:
                left += 1
            nums[right] = nums[left]
        nums[left] = pivot
        return left

    index = partition(nums, 0, len(nums) - 1)
    while len(nums) - index != k:
        if len(nums) - index < k:
            index = partition(nums, 0, index - 1)
        else:
            index = partition(nums, index + 1, len(nums) - 1)
    return nums[index]
```

## 三面
1. 项目相关。几个人做，怎么分工，有什么收获，有什么难点，都怎么解决的。
- 略
2. 有一个场景，淘宝商品分类，类目可能非常多，成千上万，样本及其不均衡，你会怎么做。
- 上采样。
- 数据增强。
- 远程监督。
- 找数据。  
- 模型层面没想到，后来搜了一下，可以参考few-shot learning, meta learning。
3. 有没有了解过元学习。
- 没有。
4. 有没有了解过图神经网络。
- 没有。

## 总结
需要好好看看职位的job description。把相关的知识了解一遍，通常会问一下他们可能会用到但是不是很热门的知识。例如这个岗位中知识图谱相关的知识，元学习。
